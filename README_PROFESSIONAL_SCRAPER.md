# ğŸ¤– Professional Web Scraper

## One-Command Solution

```bash
python scripts/auto_scraper_workflow.py <URL>
```

## What It Does

1. **Analyzes** the website structure automatically
2. **Generates** a custom scraper for that specific site
3. **Extracts** all data and saves to CSV
4. **Analyzes** the data with statistics
5. **Creates** a professional PDF report

## Example

```bash
python scripts/auto_scraper_workflow.py http://quotes.toscrape.com
```

**Output**: 
- âœ… Custom scraper script
- âœ… Extracted data (CSV + JSON)
- âœ… Data analysis with charts
- âœ… Professional PDF report (auto-opens)

## Features

- ğŸ” **Intelligent Analysis**: Learns website structure automatically
- ğŸ¯ **Custom Generation**: Creates optimized scraper for each site
- ğŸ“Š **Data Insights**: Statistics, patterns, and visualizations
- ğŸ“„ **PDF Reports**: Professional reports with charts and analysis
- âš¡ **Fully Automated**: Zero manual configuration required

## Requirements

```bash
pip install requests beautifulsoup4 lxml pandas matplotlib seaborn reportlab
```

## More Info

See [PROFESSIONAL_SCRAPER_WORKFLOW.md](docs/PROFESSIONAL_SCRAPER_WORKFLOW.md) for complete documentation.

---

**Just provide a URL, get a complete analysis report!**
