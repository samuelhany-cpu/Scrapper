"""
Quick Test Script for EgyptAir Scraper
Tests a single route to verify the scraper works before running full scrape
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.egyptair_scraper import EgyptAirFlightScraper
from src.logger import ScraperLogger
from datetime import datetime, timedelta


def main():
    print("="*80)
    print(" "*20 + "ğŸ§ª EGYPTAIR SCRAPER TEST")
    print("="*80)
    print()
    print("This will test the scraper on a single route:")
    print("  ğŸ“ Cairo (CAI) â†’ Dubai (DXB)")
    print("  ğŸ“… Today's date")
    print()
    print("This will verify:")
    print("  âœ“ Firefox WebDriver works")
    print("  âœ“ Website can be accessed")
    print("  âœ“ Form filling works")
    print("  âœ“ Data extraction works")
    print("  âœ“ Anti-bot detection is effective")
    print()
    print("="*80)
    
    input("\nPress Enter to start test...")
    
    # Initialize logger and scraper
    logger = ScraperLogger('egyptair_test')
    scraper = EgyptAirFlightScraper(logger)
    
    try:
        print("\nğŸš€ Starting test scrape...")
        print("="*80)
        
        # Setup driver
        scraper.setup_driver()
        print("âœ… Firefox WebDriver initialized successfully")
        
        # Get destinations
        destinations = scraper.get_all_destinations()
        print(f"âœ… Loaded {len(destinations)} destinations")
        
        # Find Cairo and Dubai
        cairo = next((d for d in destinations if d['code'] == 'CAI'), None)
        dubai = next((d for d in destinations if d['code'] == 'DXB'), None)
        
        if not cairo or not dubai:
            print("âŒ Could not find Cairo or Dubai in destinations")
            return
        
        # Test search
        today = datetime.now()
        print(f"\nğŸ” Testing search: {cairo['name']} â†’ {dubai['name']} on {today.strftime('%Y-%m-%d')}")
        print("â³ This may take 30-60 seconds with human-like delays...")
        
        flights = scraper.search_flights(cairo, dubai, today)
        
        print("\n" + "="*80)
        print("ğŸ“Š TEST RESULTS")
        print("="*80)
        
        if flights:
            print(f"âœ… SUCCESS! Found {len(flights)} flight(s)")
            print("\nğŸ“ Sample flight data:")
            for i, flight in enumerate(flights[:3], 1):  # Show first 3 flights
                print(f"\n  Flight {i}:")
                print(f"    Flight Number: {flight.get('flight_number', 'N/A')}")
                print(f"    Departure: {flight.get('departure_time', 'N/A')}")
                print(f"    Arrival: {flight.get('arrival_time', 'N/A')}")
                print(f"    Duration: {flight.get('duration', 'N/A')}")
                print(f"    Stops: {flight.get('stops', 'N/A')}")
            
            if len(flights) > 3:
                print(f"\n  ... and {len(flights) - 3} more flight(s)")
            
            # Save test results
            scraper.all_flights = flights
            filepath = scraper.save_to_csv(f"egyptair_test_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv")
            print(f"\nğŸ’¾ Test data saved to: {filepath}")
            
            print("\n" + "="*80)
            print("ğŸ‰ TEST PASSED!")
            print("="*80)
            print("\nThe scraper is working correctly. You can now run the full scrape:")
            print("  python scripts\\run_egyptair_scraper.py")
        else:
            print("âš ï¸  No flights found")
            print("\nPossible reasons:")
            print("  â€¢ No flights on this route today")
            print("  â€¢ Website structure changed")
            print("  â€¢ Bot detection triggered")
            print("\nğŸ’¡ Try:")
            print("  â€¢ Running test again (may be temporary issue)")
            print("  â€¢ Checking if EgyptAir website is accessible")
            print("  â€¢ Checking logs for detailed error messages")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Test interrupted by user")
    
    except Exception as e:
        print(f"\n\nâŒ TEST FAILED with error: {e}")
        print("\nCheck logs for details:")
        print(f"  {scraper.logger.log_file if hasattr(scraper, 'logger') else 'logs/scraper.log'}")
    
    finally:
        if scraper.driver:
            scraper.driver.quit()
            print("\nğŸ”’ Browser closed")
    
    print("\n" + "="*80)
    input("\nPress Enter to exit...")


if __name__ == "__main__":
    main()
