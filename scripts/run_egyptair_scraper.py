"""
EgyptAir Comprehensive Worldwide Flight Scraper Runner Script

This script runs the EgyptAir flight schedule scraper to collect
COMPREHENSIVE flight data for ALL routes worldwide over a full year period.

Features:
- ğŸŒ Covers 100+ worldwide destinations across all continents
- ğŸ‡ªğŸ‡¬ All Egyptian cities as origins (Cairo, Alexandria, Sharm El-Sheikh, etc.)
- ğŸ”„ Bidirectional routes (Egypt â†’ World AND World â†’ Egypt)
- ğŸ¤– Human-like behavior with Firefox stealth mode
- ğŸ“… Full year coverage with customizable date intervals
- ğŸ’¾ Auto-saves progress every 20 routes
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.egyptair_scraper import EgyptAirFlightScraper
from src.logger import ScraperLogger
from datetime import datetime


def main():
    print("="*100)
    print(" "*25 + "ğŸŒ EGYPTAIR COMPREHENSIVE WORLDWIDE FLIGHT SCRAPER ğŸŒ")
    print("="*100)
    print()
    print("ğŸ“‹ This will scrape EgyptAir flight schedules for ALL routes worldwide over a full year.")
    print()
    print("ğŸ¯ Coverage:")
    print("   â€¢ 100+ worldwide destinations (all continents)")
    print("   â€¢ Egypt, Middle East, Europe, Africa, Asia, Americas, Oceania")
    print("   â€¢ ALL Egyptian cities as origins (Cairo, Alexandria, etc.)")
    print("   â€¢ Bidirectional routes (outbound AND inbound)")
    print()
    print("ğŸ¤– Anti-Detection Features:")
    print("   â€¢ Firefox browser with stealth mode")
    print("   â€¢ Human-like typing and mouse movements")
    print("   â€¢ Random delays (3-60 seconds)")
    print("   â€¢ Periodic breaks to simulate real user")
    print()
    print("ğŸ’¾ Data Collection:")
    print("   â€¢ Flight numbers, times, duration, stops, aircraft")
    print("   â€¢ Auto-saves progress every 20 routes")
    print("   â€¢ Exports to CSV with UTF-8 encoding")
    print()
    print("â±ï¸  ESTIMATED TIME:")
    
    # Get user preference
    print("\nğŸ“… Select date interval:")
    print("   1. Daily (365 days) - COMPREHENSIVE but SLOW (est. 50-100 hours)")
    print("   2. Every 3 days (122 days) - Detailed (est. 15-30 hours)")
    print("   3. Weekly (52 weeks) - Balanced (est. 4-8 hours) [RECOMMENDED]")
    print("   4. Every 2 weeks (26 samples) - Quick (est. 2-4 hours)")
    print("   5. Monthly (12 samples) - Fast (est. 1-2 hours)")
    
    choice = input("\nChoose interval (1-5, default=3): ").strip()
    
    interval_map = {
        '1': (1, 'Daily'),
        '2': (3, 'Every 3 days'),
        '3': (7, 'Weekly'),
        '4': (14, 'Every 2 weeks'),
        '5': (30, 'Monthly')
    }
    
    days_interval, interval_name = interval_map.get(choice, (7, 'Weekly'))
    
    print(f"\nâœ… Selected: {interval_name} sampling ({365//days_interval} dates)")
    
    # Ask about bidirectional
    print("\nğŸ”„ Check both directions?")
    print("   YES: Egyptâ†’World AND Worldâ†’Egypt (recommended, 2x routes)")
    print("   NO: Only Egyptâ†’World (faster)")
    
    bidirectional = input("\nCheck both directions? (yes/no, default=yes): ").strip().lower()
    check_both = bidirectional not in ['no', 'n']
    
    print(f"âœ… Bidirectional: {'YES' if check_both else 'NO'}")
    
    print("\n" + "="*100)
    print("âš ï¸  WARNING: This is a comprehensive scrape!")
    print("   â€¢ Will take several hours to complete")
    print("   â€¢ Progress is auto-saved every 20 routes")
    print("   â€¢ You can stop anytime with Ctrl+C")
    print("   â€¢ Make sure you have Firefox installed")
    print("="*100)
    
    response = input("\nğŸš€ Ready to start? (yes/no): ").strip().lower()
    if response not in ['yes', 'y']:
        print("âŒ Scraping cancelled.")
        return
    
    print("\n" + "="*100)
    print(f"ğŸš€ STARTING SCRAPER at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*100 + "\n")
    
    # Initialize logger and scraper
    logger = ScraperLogger('egyptair_worldwide')
    scraper = EgyptAirFlightScraper(logger)
    
    start_time = datetime.now()
    
    try:
        # Run the comprehensive worldwide scraper
        flights = scraper.scrape_all_routes_year(
            days_interval=days_interval,
            check_both_directions=check_both
        )
        
        end_time = datetime.now()
        duration = end_time - start_time
        
        print("\n" + "="*100)
        print("âœ… SCRAPING COMPLETED SUCCESSFULLY!")
        print("="*100)
        
        if flights:
            # Save final results
            filepath = scraper.save_to_csv()
            
            # Get comprehensive statistics
            stats = scraper.get_statistics()
            
            print(f"\nğŸ“Š COMPREHENSIVE STATISTICS:")
            print(f"   {'='*90}")
            print(f"   â±ï¸  Duration: {duration.total_seconds()/3600:.2f} hours ({duration.total_seconds()/60:.1f} minutes)")
            print(f"   âœˆï¸  Total Flights Found: {stats['total_flights']:,}")
            print(f"   ğŸ›« Unique Routes: {stats['unique_routes']:,}")
            print(f"   ğŸ”¢ Unique Flight Numbers: {stats['unique_flight_numbers']}")
            print(f"   ğŸ“… Date Range: {stats['date_range']}")
            print(f"   ğŸŒ Origin Airports: {len(stats['origins'])} cities")
            print(f"   ğŸŒ Destination Airports: {len(stats['destinations'])} cities")
            print(f"   {'='*90}")
            
            print(f"\nğŸ“ Origins ({len(stats['origins'])}):")
            print(f"   {', '.join(stats['origins'][:20])}...")
            
            print(f"\nğŸ“ Destinations ({len(stats['destinations'])}):")
            print(f"   {', '.join(stats['destinations'][:20])}...")
            
            print(f"\nğŸ’¾ Final data saved to:")
            print(f"   ğŸ“„ {filepath}")
            
            print("\n" + "="*100)
            print("ğŸ‰ SUCCESS! All EgyptAir flight data has been collected.")
            print("="*100)
        else:
            print("\nâš ï¸  WARNING: No flights were found.")
            print("   â€¢ Check if EgyptAir website is accessible")
            print("   â€¢ Check logs for detailed error messages")
            print("   â€¢ Try running again with different date range")
    
    except KeyboardInterrupt:
        print("\n\n" + "="*100)
        print("âš ï¸  SCRAPING INTERRUPTED BY USER (Ctrl+C)")
        print("="*100)
        
        if scraper.all_flights:
            print(f"\nğŸ’¾ Saving {len(scraper.all_flights)} flights collected so far...")
            filepath = scraper.save_to_csv(f"egyptair_partial_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv")
            print(f"âœ… Partial data saved to: {filepath}")
        else:
            print("\nâŒ No data to save.")
    
    except Exception as e:
        print(f"\n\nâŒ ERROR: {e}")
        print("Check logs for details.")
        
        if scraper.all_flights:
            print(f"\nğŸ’¾ Saving {len(scraper.all_flights)} flights collected before error...")
            filepath = scraper.save_to_csv(f"egyptair_error_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv")
            print(f"âœ… Data saved to: {filepath}")
    
    finally:
        input("\nPress Enter to exit...")


if __name__ == "__main__":
    main()
